# Deep Learning Specialization

### Table of Contents
1. [My Learnings from the Specialization](#Introduction)
2. [Instructions for using the files](#Instruction)
3. [Course Descriptions](#Description)
4. [Results from programming assignments](#Results)
5. [Disclaimer](#Disc)

## My Learnings from the Specialization<a name="Introduction"></a>
Instructor of the specialization: [Andrew Ng](http://www.andrewng.org/).

In this five course series, I learned about the foundations of Deep Learning by implementing vectorized neural networks **(MLP, CNN, RNN, LSTM)** and optimization algorithms **(SGD, RMSprop, Adam)** from scratch in Python, building and training deep neural networks in **TensorFlow and Keras**, identifying key parameters in network architecture for hyperparameter tuning.

I learned about the best practices to train and develop test sets and analyzed bias/variance for building DL applications, diagnosed and used strategies for reducing errors in ML systems, understand complex ML settings and used **transfer learning for image classification tasks**.

I learned to build CNN models **(YOLO for object detection, Siamese network for face verification and face recognition)** for visual detection and recognition tasks and neural style transfer to generate art. I learned about RNNs, GRUs, and LSTMs, applied RNNs to character-level language modeling, **Seq2seq model for Neural Machine Translation with attention**. 

## Instructions for using the files<a name="Instruction"></a>
This repository contains all my work for this specialization. All the code base, quiz questions, screenshot, and images, are taken from, unless specified, [Deep Learning Specialization on Coursera](https://www.coursera.org/specializations/deep-learning?utm_source=gg&utm_medium=sem&utm_campaign=17-DeepLearning-US&utm_content=17-DeepLearning-US&campaignid=904733485&adgroupid=49070439496&device=c&keyword=neural%20network%20for%20machine%20learning&matchtype=b&network=g&devicemodel=&adpostion=&creativeid=415429113789&hide_mobile_promo&gclid=EAIaIQobChMI5_CtgI_t7wIVPObjBx0xuwp6EAAYASAAEgKLhvD_BwE).
Clone the repository to use.

## Course Descriptions<a name="Description"></a>
1. [C1 - Neural Networks and Deep Learning](https://github.com/Ankit-Kumar-Saini/Deep_Learning_Specialization/tree/main/C1%20-%20Neural%20Networks%20and%20Deep%20Learning).
**Course Objective:**
This course focuses on vectorized implementation of neural networks in Python.
	**Week 1: Introduction to deep learning**
		- Be able to explain the major trends driving the rise of deep learning, and understand where and how it is applied today.

	**Week 2: Neural Networks Basics**
		- Python Basics with Numpy and Logistic Regression with a Neural Network mindset.

	**Week 3: Shallow neural networks**
		- Understand the key parameters in a neural network's architecture. Planar data classification with a hidden layer

	**Week 4: Deep Neural Networks**
		- Understand the key computations underlying deep learning, use them to build and train deep neural networks, and apply it to computer vision.

2. [C2 - Improving Deep Neural Networks Hyperparameter tuning, Regularization and Optimization](https://github.com/Ankit-Kumar-Saini/Deep_Learning_Specialization/tree/main/C2%20-%20Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization).
**Course Objective:**
This course teaches the "magic" of getting deep learning to work well. Rather than the deep learning process being a black box, you will understand what drives performance, and be able to more systematically get good results. 
	**Week 1: Practical aspects of Deep Learning**
		- Understand industry best-practices for building deep learning applications. Be able to effectively use the common neural network "tricks", including initialization, L2 and dropout regularization, Batch normalization, gradient checking along with implementation.

	**Week 2: Optimization algorithms**
		- Be able to implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence. 

	**Week 3: Hyperparameter tuning, Batch Normalization and Programming Frameworks**
	- Understand new best-practices for the deep learning era of how to set up train/dev/test sets and analyze bias/variance. 
	- Implement a neural network in TensorFlow.

3. [C3 - Structuring Machine Learning Projects](https://github.com/Ankit-Kumar-Saini/Deep_Learning_Specialization/tree/main/C3%20-%20Structuring%20Machine%20Learning%20Projects).
**Course Objective:**
	-Understand how to diagnose errors in a machine learning system, and 
	-Be able to prioritize the most promising directions for reducing error
	-Understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance
	-Know how to apply end-to-end learning, transfer learning, and multi-task learning
**There is no Program Assigments for this course. But this course comes with very interesting case study quizzes**
4. [C4 - Convolutional Neural Networks](https://github.com/Ankit-Kumar-Saini/Deep_Learning_Specialization/tree/main/C4%20-%20Convolutional%20Neural%20Networks).
  Objectives: 
  + Understand how to build a convolutional neural network, including recent variations such as residual networks.
  + Know how to apply convolutional networks to visual detection and recognition tasks.
  + Know to use neural style transfer to generate art.
  + Be able to apply these algorithms to a variety of image, video, and other 2D or 3D data.
	**Week 1 - Foundations of Convolutional Neural Networks**
		- Build Convolutional Model in python from scratch.

	**Week 2 - Deep convolutional models: case studies**
		- Build Residual Network in Keras.

	**Week 3 - Object detection**
		- Learn how to apply your knowledge of CNNs to one of the toughest but hottest field of computer vision: Object detection. Autonomous driving application - Car detection.

	**Week 4 - Special applications: Face recognition & Neural style transfer**
		- Discover how CNNs can be applied to multiple fields, including art generation and face recognition. 
		- Build Face Recognition model for the Happy House. Implement Art Generation with Neural Style Transfer.
5. [C5 - Sequence Models](https://github.com/Ankit-Kumar-Saini/Deep_Learning_Specialization/tree/main/C5%20-%20Sequence%20Models).
**Course Objective:**
  - Understand how to build and train Recurrent Neural Networks (RNNs), and commonly-used variants such as GRUs and LSTMs.
  - Be able to apply sequence models to natural language problems, including text synthesis. 
  - Be able to apply sequence models to audio applications, including speech recognition and music synthesis.
	**Week 1 - Recurrent Neural Networks**
		- Build a Recurrent Neural Network in python from scratch. Implement Character-Level Language Modeling to generate Dinosaur names. Generate music to Improvise a Jazz Solo with an LSTM Network.

	**Week 2 - Natural Language Processing & Word Embeddings**
		- Using word vector representations and embedding layers you can train recurrent neural networks with outstanding performances in a wide variety of industries. Examples of applications are sentiment analysis, named entity recognition and machine translation.

	**Week 3 - Sequence models & Attention mechanism**
		- Sequence models can be augmented using an attention mechanism. This algorithm will help your model understand where it should focus its attention given a sequence of inputs.
		- Implement Neural machine translation with attention and Trigger word detection.
 


  
  





